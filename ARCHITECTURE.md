# ðŸ—ï¸ Architecture Documentation

**Project:** Vicidial Call Analysis Platform
**Version:** 2.0
**Last Updated:** 2025-10-13

---

## ðŸ“ System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        STREAMLIT WEB UI                         â”‚
â”‚                         (app.py + pages/)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚                â”‚
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Vicidial   â”‚  â”‚    Local     â”‚  â”‚ Google Drive â”‚
â”‚   Database   â”‚  â”‚    Folder    â”‚  â”‚     API      â”‚
â”‚   (MySQL)    â”‚  â”‚   (Audio)    â”‚  â”‚   (Audio)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                 â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Audio Files (.mp3) â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Transcription      â”‚
              â”‚  (OpenAI Whisper)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Transcript (.txt)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                     â”‚
              â–¼                     â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Campaign   â”‚      â”‚   Analysis   â”‚
       â”‚   Context    â”‚â”€â”€â”€â”€â”€â–¶â”‚   (GPT-4)    â”‚
       â”‚  + Docs      â”‚      â”‚              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  Reports (CSV/Excel) â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“‚ Directory Structure

```
Analyze-calls/
â”œâ”€â”€ app.py                     # Entry point - Dashboard
â”œâ”€â”€ .cursorrules               # AI assistant rules
â”œâ”€â”€ README.md                  # Main documentation
â”œâ”€â”€ ARCHITECTURE.md            # This file
â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚
â”œâ”€â”€ pages/                     # UI Pages (Streamlit)
â”‚   â”œâ”€â”€ 1_Pipeline_Komplet.py      # Main workflow orchestrator
â”‚   â”œâ”€â”€ 2_Raporte.py                # Smart Reports UI
â”‚   â”œâ”€â”€ 3_Rezultatet_e_Listave.py  # List analysis UI
â”‚   â”œâ”€â”€ 4_Tools.py                  # Individual tools (tabs)
â”‚   â””â”€â”€ 5_Settings.py               # Settings + campaigns UI
â”‚
â”œâ”€â”€ core/                      # Business Logic (pure Python)
â”‚   â”œâ”€â”€ analysis_llm.py            # GPT-4 analysis engine
â”‚   â”œâ”€â”€ campaign_manager.py        # Campaign CRUD + documents
â”‚   â”œâ”€â”€ config.py                  # Configuration loader
â”‚   â”œâ”€â”€ constants.py               # Global constants
â”‚   â”œâ”€â”€ db_vicidial.py             # MySQL connection
â”‚   â”œâ”€â”€ downloader_vicidial.py     # Audio downloader
â”‚   â”œâ”€â”€ drive_io.py                # Google Drive API
â”‚   â”œâ”€â”€ prefix_it.py               # Italian prefix detector
â”‚   â”œâ”€â”€ reporting_excel.py         # Excel generator
â”‚   â”œâ”€â”€ status_settings.py         # Status cost settings
â”‚   â”œâ”€â”€ transcription_audio.py     # Transcription orchestrator
â”‚   â”œâ”€â”€ transcription_whisper.py   # Whisper API wrapper
â”‚   â”œâ”€â”€ voip_rates.py              # VoIP rate manager
â”‚   â””â”€â”€ prompt_analysis_template.txt  # LLM prompt template
â”‚
â”œâ”€â”€ config/                    # Configuration Files
â”‚   â”œâ”€â”€ campaign_contexts.json     # Campaign definitions
â”‚   â”œâ”€â”€ settings.json              # App settings
â”‚   â””â”€â”€ voip_rates.json            # VoIP pricing
â”‚
â”œâ”€â”€ assets/                    # Static Assets
â”‚   â”œâ”€â”€ campaigns/                 # Campaign documents
â”‚   â”‚   â””â”€â”€ {campaign_id}/
â”‚   â”‚       â”œâ”€â”€ documents/         # Original files
â”‚   â”‚       â””â”€â”€ extracted_text.txt # Extracted text
â”‚   â””â”€â”€ protrade.jpg               # Logo
â”‚
â”œâ”€â”€ data/                      # Reference Data
â”‚   â””â”€â”€ it_prefixes.csv           # Italian phone prefixes
â”‚
â”œâ”€â”€ out_analysis/              # Output Directory (generated)
â”‚   â””â”€â”€ {session_name}/
â”‚       â”œâ”€â”€ Transkripte/          # Transcripts by agent
â”‚       â”œâ”€â”€ call_analysis.csv
â”‚       â”œâ”€â”€ agent_summary_weekly.csv
â”‚       â””â”€â”€ Raport_Analize.xlsx
â”‚
â””â”€â”€ venv/                      # Virtual environment (ignored)
```

---

## ðŸ”„ Data Flow

### 1. User Interaction Flow

```
User â†’ Dashboard (app.py)
       â†“
       Select: Pipeline / Tools / Reports / Settings
       â†“
       Pipeline Komplet (pages/1_Pipeline_Komplet.py)
       â†“
       [Select Source] â†’ [Select Campaign] â†’ [Configure] â†’ [Run]
```

### 2. Pipeline Execution Flow

```mermaid
sequenceDiagram
    participant U as User (UI)
    participant P as Pipeline
    participant D as Downloader
    participant T as Transcriber
    participant C as Campaign Mgr
    participant A as Analyzer (LLM)
    participant R as Reporter

    U->>P: Start Pipeline (source, campaign, filters)
    P->>D: Download audio
    D-->>P: Audio files []
    P->>T: Transcribe audio
    T-->>P: Transcripts []
    P->>C: Get campaign context
    C-->>P: Hints + documents text
    P->>A: Analyze (transcripts + context)
    A-->>P: Analysis results {}
    P->>R: Generate reports
    R-->>P: CSV + Excel files
    P->>U: Download links
```

### 3. Campaign Context Flow

```
User creates campaign â†’ Settings Page (5_Settings.py)
                        â†“
                 campaign_manager.create_campaign()
                        â†“
                 Saves to config/campaign_contexts.json
                        â†“
                 Creates folder assets/campaigns/{id}/
                        â†“
User uploads docs â†’ campaign_manager.add_document_to_campaign()
                        â†“
                 Extracts text (PDF/DOCX/TXT)
                        â†“
                 Saves to extracted_text.txt
                        â†“
Pipeline runs â†’ campaign_manager.get_campaign_hints()
                        â†“
                 Returns: hints + full document text
                        â†“
                 analysis_llm.analyze_agent_transcripts()
                        â†“
                 Sends to GPT-4 with campaign context
```

---

## ðŸ§© Module Dependencies

### Core Module Graph

```
config.py (base)
    â†“
constants.py
    â†“
campaign_manager.py â”€â”€â”€â”
    â†“                  â”‚
db_vicidial.py         â”‚
    â†“                  â”‚
downloader_vicidial.py â”‚
    â†“                  â”‚
transcription_audio.py â”‚
    â†“                  â”‚
analysis_llm.py â†â”€â”€â”€â”€â”€â”€â”˜
    â†“
reporting_excel.py
```

### Pages Dependencies

```
app.py
    â†“
pages/1_Pipeline_Komplet.py
    â”œâ”€â†’ core/downloader_vicidial.py
    â”œâ”€â†’ core/transcription_audio.py
    â”œâ”€â†’ core/campaign_manager.py
    â”œâ”€â†’ core/analysis_llm.py
    â””â”€â†’ core/reporting_excel.py

pages/4_Tools.py
    â”œâ”€â†’ (Tab 1) core/db_vicidial.py
    â”œâ”€â†’ (Tab 2) core/drive_io.py
    â””â”€â†’ (Tab 3) core/transcription_audio.py

pages/5_Settings.py
    â”œâ”€â†’ core/campaign_manager.py
    â”œâ”€â†’ core/voip_rates.py
    â””â”€â†’ core/status_settings.py
```

---

## ðŸŽ¨ UI Layer Architecture

### Separation of Concerns

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           UI LAYER (pages/)             â”‚
â”‚  - User input collection                â”‚
â”‚  - Display & formatting                 â”‚
â”‚  - Streamlit widgets                    â”‚
â”‚  - Progress bars & status               â”‚
â”‚  - NO business logic                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ Calls functions
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        LOGIC LAYER (core/)              â”‚
â”‚  - Data processing                      â”‚
â”‚  - API calls (OpenAI, Drive, DB)       â”‚
â”‚  - Business rules                       â”‚
â”‚  - Pure Python (NO Streamlit imports)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ Reads/writes
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       DATA LAYER (config/, assets/)     â”‚
â”‚  - JSON configurations                  â”‚
â”‚  - Document storage                     â”‚
â”‚  - Output files                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Principle: **UI NEVER contains business logic**

âŒ **BAD (Logic in UI):**
```python
# pages/1_Pipeline_Komplet.py
if st.button("Analyze"):
    # Extract text from PDF
    with open(pdf_file, 'rb') as f:
        reader = PyPDF2.PdfReader(f)
        text = reader.pages[0].extract_text()

    # Call OpenAI
    response = openai.chat.completions.create(...)

    # Parse response
    data = json.loads(response.content)
```

âœ… **GOOD (Logic in core):**
```python
# pages/1_Pipeline_Komplet.py
if st.button("Analyze"):
    result = analyze_campaign(campaign_id, audio_files)
    st.success(f"Done! {len(result)} calls analyzed")

# core/analysis_llm.py
def analyze_campaign(campaign_id, audio_files):
    # All the logic here
    ...
    return results
```

---

## ðŸ”Œ External Integrations

### OpenAI API

**Used for:**
- Transcription: `gpt-4o-transcribe` or `whisper-1`
- Analysis: `gpt-4.1` or configured model

**Flow:**
```python
core/transcription_audio.py
    â†’ core/transcription_whisper.py
        â†’ OpenAI API (audio â†’ text)

core/analysis_llm.py
    â†’ OpenAI API (text + prompt â†’ structured feedback)
```

**Configuration:**
- API Key: `.streamlit/secrets.toml` or env var
- Models: Configurable in `core/constants.py`

### Vicidial MySQL Database

**Used for:**
- Fetch call recordings metadata
- Filter by date, campaign, agent
- Get call duration, status

**Flow:**
```python
pages/1_Pipeline_Komplet.py (user filters)
    â†’ core/db_vicidial.py (query builder)
        â†’ MySQL connection
            â†’ Returns: [{call_id, location, agent, ...}, ...]
    â†’ core/downloader_vicidial.py (download files)
```

**Configuration:**
- Credentials: `.streamlit/secrets.toml`
- Multiple DB support: `db` and `db2`

### Google Drive API

**Used for:**
- Download audio files from shared folders
- Upload processed files back to Drive

**Flow:**
```python
pages/1_Pipeline_Komplet.py (Drive folder ID)
    â†’ core/drive_io.py
        â†’ Google Drive API (OAuth2)
            â†’ Download files
            â†’ Create folder structure
            â†’ Upload files
```

**Configuration:**
- OAuth2 credentials: `token.json` (auto-generated)
- Parent folder: `.streamlit/secrets.toml`

---

## ðŸ’¾ Data Storage

### Configuration Files

| File | Purpose | Format |
|------|---------|--------|
| `config/campaign_contexts.json` | Campaign definitions | JSON |
| `config/settings.json` | App settings (status costs, thresholds) | JSON |
| `config/voip_rates.json` | VoIP pricing | JSON |
| `.streamlit/secrets.toml` | API keys, credentials | TOML |

### Campaign Storage

```
assets/campaigns/{campaign_id}/
â”œâ”€â”€ documents/
â”‚   â”œâ”€â”€ script.pdf           # Original file
â”‚   â”œâ”€â”€ objections.docx      # Original file
â”‚   â””â”€â”€ offer.pdf            # Original file
â””â”€â”€ extracted_text.txt       # Combined extracted text
```

**Why separate extracted_text.txt?**
- Performance: No need to re-extract on every analysis
- Caching: Text is ready for LLM
- Simplicity: Single file to read for all documents

### Output Storage

```
out_analysis/{session_name}/
â”œâ”€â”€ Transkripte/
â”‚   â”œâ”€â”€ Agent1/
â”‚   â”‚   â”œâ”€â”€ call001.txt
â”‚   â”‚   â””â”€â”€ call002.txt
â”‚   â””â”€â”€ Agent2/
â”‚       â””â”€â”€ call003.txt
â”œâ”€â”€ call_analysis.csv          # Per-call results
â”œâ”€â”€ agent_summary_weekly.csv   # Per-agent summary
â””â”€â”€ Raport_Analize.xlsx        # Formatted Excel report
```

---

## ðŸ” Security Considerations

### Secrets Management

**NEVER commit:**
- `.streamlit/secrets.toml`
- `config.py` (if contains credentials)
- `*.env` files
- `token.json` (OAuth tokens)

**Store in:**
```toml
# .streamlit/secrets.toml
OPENAI_API_KEY = "sk-..."

[db]
host = "xxx.xxx.xxx.xxx"
user = "user"
password = "pass"
database = "asterisk"

[drive]
parent_id = "folder-id"
```

### Input Validation

**Always validate:**
- File sizes (max 5MB)
- File types (whitelist extensions)
- SQL parameters (parameterized queries)
- User-provided paths (prevent directory traversal)
- Campaign names (alphanumeric + spaces)

**Example:**
```python
# core/campaign_manager.py
if file_size_mb > MAX_FILE_SIZE_MB:
    raise ValueError(f"File too large: {file_size_mb:.2f}MB")

if not is_valid_extension(filename):
    raise ValueError(f"Unsupported file type: {ext}")
```

---

## ðŸš€ Performance Optimizations

### Caching Strategy

1. **Transcription Caching**
   - Check if `.txt` exists before transcribing
   - Option: `reuse_existing=True` (default)

2. **Streamlit Caching**
   ```python
   @st.cache_data
   def load_campaigns():
       return get_all_campaigns()
   ```

3. **Document Text Caching**
   - Extracted once â†’ saved to `extracted_text.txt`
   - No re-extraction on subsequent analyses

### Batch Processing

- Group transcripts by agent before analysis
- Single LLM call per agent (not per call)
- Reduces API calls from N to ~10-20

### Progress Feedback

- Update progress bars every item
- Display current operation
- Show percentage completed

```python
prog = st.progress(0, text="Starting...")
for i, item in enumerate(items):
    process(item)
    percent = int((i+1)/total*100)
    prog.progress(percent, text=f"Processing: {i+1}/{total}")
```

---

## ðŸ§ª Testing Strategy

### Manual Testing Checklist

- [ ] Dashboard loads without errors
- [ ] Pipeline with Vicidial source
- [ ] Pipeline with local folder
- [ ] Pipeline with Google Drive
- [ ] Campaign creation
- [ ] Document upload (PDF, DOCX, TXT)
- [ ] Campaign selection in pipeline
- [ ] Report generation
- [ ] Download reports

### Edge Cases

- [ ] Empty audio folder
- [ ] Invalid API key
- [ ] Database connection failure
- [ ] Large files (>5MB)
- [ ] Special characters in names
- [ ] Concurrent pipeline runs

### Automated Testing (Future)

```python
# tests/test_campaign_manager.py
def test_create_campaign():
    campaign = create_campaign(name="Test")
    assert "id" in campaign
    assert campaign["name"] == "Test"

def test_add_document_exceeds_limit():
    # Add 3 documents
    # Try to add 4th
    with pytest.raises(ValueError):
        add_document_to_campaign(...)
```

---

## ðŸ“ˆ Scalability Considerations

### Current Limitations

- **Single-threaded:** Streamlit runs one request at a time
- **Local storage:** Files stored on server disk
- **No database:** Config in JSON files
- **OpenAI rate limits:** ~3500 requests/min (GPT-4)

### Future Improvements

1. **Database Migration**
   - Move from JSON to PostgreSQL/MongoDB
   - Better concurrency and querying

2. **Async Processing**
   - Use Celery for background tasks
   - Queue system for pipeline jobs

3. **Cloud Storage**
   - S3/GCS for audio and documents
   - Reduce local disk usage

4. **Horizontal Scaling**
   - Multiple Streamlit instances
   - Load balancer
   - Shared database

---

## ðŸ”§ Extension Points

### Adding a New Feature

**Example: Add "Call Sentiment" field**

1. **Update LLM prompt** (`core/prompt_analysis_template.txt`)
   ```
   Add field: "sentiment": "positive/neutral/negative"
   ```

2. **Update analysis function** (`core/analysis_llm.py`)
   ```python
   data["sentiment"] = data.get("sentiment", "neutral")
   ```

3. **Update report** (`core/reporting_excel.py`)
   ```python
   df["sentiment"] = results["sentiment"]
   ```

4. **Update UI** (optional display in UI)

### Adding a New Page

1. Create `pages/6_New_Feature.py`
2. Follow naming convention: `N_Title.py`
3. Import from `core/` for logic
4. Update dashboard links in `app.py`

### Adding a New Data Source

1. Create `core/source_name.py`
2. Implement interface:
   ```python
   def fetch_audio_files(params) -> List[Path]:
       ...
   ```
3. Integrate in `pages/1_Pipeline_Komplet.py`

---

## ðŸ“ Maintenance Guide

### Regular Tasks

- **Weekly:** Review error logs
- **Monthly:** Update dependencies
- **Quarterly:** Review and cleanup old outputs

### Updating Dependencies

```bash
# Check for updates
pip list --outdated

# Update specific package
pip install --upgrade streamlit

# Update requirements.txt
pip freeze > requirements.txt
```

### Monitoring

**Key Metrics:**
- API usage (OpenAI costs)
- Storage usage (`out_analysis/` size)
- Error rates
- Average pipeline duration

---

## ðŸ†˜ Troubleshooting

### Common Issues

| Problem | Cause | Solution |
|---------|-------|----------|
| "OPENAI_API_KEY mungon" | Missing API key | Add to secrets.toml |
| "Nuk lidhet me DB" | VPN/credentials | Check VPN + secrets |
| "S'gjen audio" | Wrong path | Verify folder exists |
| Slow transcription | Large files | Check file sizes |
| Out of memory | Too many files | Reduce batch size |

### Debug Mode

Enable verbose logging:
```python
# core/config.py
DEBUG = True

# Then in code:
if DEBUG:
    st.write(f"Debug: {variable}")
```

---

## ðŸ“š Additional Resources

- **Streamlit Docs:** https://docs.streamlit.io
- **OpenAI API:** https://platform.openai.com/docs
- **Google Drive API:** https://developers.google.com/drive

---

**Maintainer:** Protrade AI
**Last Review:** 2025-10-13
**Next Review:** 2026-01-13

















